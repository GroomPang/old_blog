---
layout: post
title: "Kubernetes Strcuture"
date: 2021-12-27
categories: Kubernetes
tags: [hello, groompang, serverless, bob]
---


# 1. 마스터 노드(Kubernetes Master)
쿠버네티스 클러스터 전체를 컨트롤하는 시스템. master는 API 서버를 통해, k8s를 관리하고, 모든 컴포넌트(component)들은 API 서버를 통해서 통신한다. 이는 관리자만 접속할 수 있고, 보안 설정이 필요하다. 마스터 노드가 죽으면, 클러스터를 관리할 수 없기 때문에, 3대를 구성해서 안전성을 높이는 것이 일반적이다. 다양한 모듈이 확장성을 고려해 떨어져 있다는 특징을 갖고 있다.

Control Plane에서 해당 요소들은 개별적인 프로세스로 동작한다. 그렇다면 각 구성 요소들은 어떤 방식으로 통신을 할까? Shared memory? file?

정답은 '**모든 구성요소는 API 서버로만 통신한다**.'이다. 예를 들어, 컨트롤러 매니저가 etcd의 데이터를 변경하고 싶다면, etcd가 아니라 API 서버에 요청을 보내야 한다.

쿠버네티스 클러스터의 기능을 제어하기 때문에, control plane이 제 기능을 수행하지 못한다면, 쿠버네티스 클러스터도 마찬가지로 본래의 기능을 수행하지 못한다. 따라서, 컨트롤 플레인이 단일 실패 지점(SPOF)이 되지 않도록 가용성을 확보해야 한다.

구성 요소가 같은 노드에 존재해야 하는 워커 노드와 다르게, 컨트롤 플레인의 요소는 여러 서버에 구축될 수 있다. 따라서, 여러 노드에 컨트롤 플레인의 구성 요소 인스턴스를 여러 개 띄워 가용성을 향상시킬 수 있다. 이때 알아야 할 점은, etcd와 API 서버는 여러 인스턴스를 동시에 활성화시켜 병렬로 실행이 가능하지만, 스케줄러(scheduler)와 컨트롤러 매니저(controller manager)는 나머지 인스턴스에서 대기 상태로 유지해야 한다는 것이다. (단 하나의 노드에서만 활성화될 수 있다는 뜻인가?)


## 1.1 API 서버
![Caption](https://github.com/GroomPang/Research/blob/main/%EA%B7%B8%EB%A6%BC1.png?raw=true)

쿠버네티스의 모든 기능들을 REST API로 제공하고, 그에 대한 명령을 처리하는 부분이다. k8s 내부의 모든 컴포넌트들이 서로 호출하기 위해 사용하는 컴포넌트이다. kubectl 요청뿐만 아니라, 내부 모듈의 요청처리, 권한 체크, 요청 거부, 노드에서 실행 중인 컨테이너 로그를 확인하는 디버거 역할도 가능하다.

클라이언트가 API 서버에 리소스 생성 및 조회의 요청을 보내게 되면, 다음과 같은 과정을 거친다.

1. 요청을 보낸 클라이언트가 인증된 클라이언트인지 확인
2. 인증된 사용자가 현재 보낸 요청을 수행할 수 있는 권한이 있는지 확인
3. (리소스 생성 및 수정, 삭제) 리소스를 기존에 정의된 플러그인을 통해 수정
4. 리소스의 유효성을 확인한 후, etcd에 저장
5. 리소스의 변경 사항을 리소스를 감시하고 있는 모든 클라이언트에게 통보

### **REST란**

1. HTTP URI(Uniform Resource Identifier)를 통해 자원(Resource)을 명시하고,
2. HTTP Method(POST, GET, PUT, DELETE)를 통해
3. 해당 자원(URI)에 대한 CRUD Operation을 적용하는 것을 의미한다.

## 1.2 etcd

여러 개로 분산해서 복제가 가능하고, 안전성이 높으며, 속도가 빠르다. 단순히 값을 저장하고 읽기 뿐만 아니라, watch 기능으로 상태 변경을 체크할 수도 있다. 오직 API 서버와 통신하고, 다른 모듈들도 API 서버를 경유해서 etcd 데이터에 접근한다.

쿠버네티스에서 생성된 모든 오브젝트는 상태와 메니페스트를 영속적으로 유지해야 한다. 이를 위해서 쿠버네티스는 분산 key-value 저장소인 etcd를 사용한다. etcd는 분산된 아키텍쳐 형태를 가질 수 있으며, 이를 통해, 고가용성 및 빠른 성능을 제공한다. 쿠버네티스는 etcd v2나 v3를 모두 지원하지만, v3가 더 나은 성능을 보여주기 때문에 v3를 사용하는 것을 권장한다. 따라서, v3 기준으로 데이터가 어떻게 되는지 살펴보면 etcd는 계층적 key 구조를 통해, 쿠버네티스의 데이터를 저장한다. 이때, /registry 아래에 모든 데이터를 저장한다.

앞서 말한 것과 같이, 컨트롤 플레인 내부의 다른 컴포넌트는 API 서버를 통해서만 etcd와 통신하게 된다. 이렇게 간접적으로 데이터를 읽거나 쓰면서 다음과 같은 이점을 얻을 수 있다.

- 유효성 검사

etcd에 저장하기 전 API 서버를 통해 저장하려는 데이터의 유효성을 검증할 수 있다.

- 낙관적 동시성 제어

낙관적 동시성 제어는 데이터에 잠금을 설정해 업데이트를 막는 대신, 데이터에 버전을 포함하는 방식이다. 만약 클라이언트가 데이터를 읽고 업데이트를 제출하는 사이에 버전 번호가 변경되었다면, 해당 업데이트는 거부되고 이전에 업데이트된 내용을 읽고 다시 업데이트를 수행하게 된다.

RAFT 합의 알고리즘

분산된 etcd 클러스터는 RAFT 합의 알고리즘을 통해 데이터의 일관성을 유지하게 된다. RAFT 합의 알고리즘을 간단하게 말하자면, 클러스터에 Split Brain 현상이 발생하게 되면 **과반수가 넘는 노드가 있는 쪽만 유효한 요청을 수행**할 수 있다는 알고리즘이다. 추가적으로 etcd 인스턴스 수를 일반적으로 홀수로 배포하게 되는데, 이는 짝수인 경우 과반이 존재하지 않을 가능성이 높아지기 때문이다.

## 1.3 Scheduler

pod, 서비스 등 각 리소스들을 적절한 노드에 할당한다. **pod를 어떤 노드에 실행할 지 결정**하는데 책임을 지고 있다. node에 배치된 pod는 각 노드의 kubelet에 의해 컨테이너로 생성된다.

클라이언트가 pod를 생성하면, 리소스를 고려해 어떤 노드에 배치할 지 결정한다. 좀 더 자세히 말하면, 어떤 노드에 스케줄링될 지를 결정하며 pod의 spec을 변경하고, 이를 API 서버에게 전송한다. 최종적으로 API 서버는 워커 노드의 Kubelet에게 이 정보를 보냄으로써, pod가 해당 노드에서 생성된다.

## 1.4 Controller Manager Server

k8s의 ReplicaSet, Deployment 등 Controller를 관리하고, 적절한 노드에 할당한다. **각 컨트롤러에게 pod의 복제/배포 명령을 수행하는 것**이 임무이다.

Scheduler를 통해 pod가 스케줄링되었다면, 다음으로 해야 하는 작업은 해당 리소스를 원하는 상태(desired state)로 만드는 작업이다. 쿠버네티스에서 이러한 작업을 수행하는 컴포넌트를 Controller라고 한다. 컨트롤러 매니저는 다양한 컨트롤러들을 실행하는 역할을 담당한다.

### Controller

Controller는 **API 서버를 통해, 리소스의 변경을 감시하고 변경**하는 작업을 담당한다. 클라이언트가 선언한 spec으로 조정하며 새롭게 변경된 상태를 status에 저장한다. 쿠버네티스에는 기본적으로 제공되는 다양한 Controller가 존재한다.

1. 노드 컨트롤러: 노드를 생성하고 초기화하며 노드에 대해서 응답 여부를 체크하여 비활성화/삭제/수정을 진행합니다.
2. 레플리케이션 컨트롤러: 설정된 값보다 파드가 많이 생성될 경우 삭제, 또는 오류가 있을 경우 삭제 및 재생성하는 작업 등을 통해 지정된 수의 파드 실행을 보장합니다.
3. 엔드포인트 컨트롤러: 서비스와 파드를 연결하는 역할입니다.
4. 서비스 & 계정 컨트롤러 : 새로운 네임스페이스 및 계정에 대한 권한 및 인증을 수행하는 역할입니다.

[https://kubernetes.io/docs/concepts/overview/components/](https://kubernetes.io/docs/concepts/overview/components/)

## 1.5 Cloud Controller Manager

AWS, GCP, Azure 등 **퍼블릭 클라우드와 연동 관리하는 역할**을 담당하고 있다. 노드를 추가/삭제하고 로드밸런서를 연결하거나 볼륨을 붙일 일이 있을 때, 각 클라우드 업체의 인터페이스(aws-ELB, gcp-GLB, azure-AB)에 맞춰서 구현할 수 있다.

## 1.6 DNS

내부 위치 정보를 저장하는 DNS 서버이다. 리소스 엔드포인트를 DNS로 매핑하고 관리한다. **pod나 서비스**들은 ip를 배정받지만, **동적으로** **생성**되는 리소스이기 때문에 ip가 변경되면 dns에 위치정보를 저장한다. 새로운 리소스가 생기면 그 리소스에 대한 ip와 dns이름을 등록하고, dns 이름 기반으로 리소스를 접근한다.

그림에는 빠져있는데, 쿠버네티스는 리소스의 엔드포인트(Endpoint)를 DNS로 맵핑하고 관리한다. Pod나 서비스등은 IP를 배정받는데, 동적으로 생성되는 리소스이기 때문에 그 IP 주소가 그때마다 변경이 되기 때문에, 그 리소스에 대한 위치 정보가 필요한데, 이러한 패턴을 Service discovery 패턴이라고 하는데, 쿠버네티스에서는 이를 내부 DNS서버를 두는 방식으로 해결하였다.

새로운 리소스가 생기면, 그 리소스에 대한 IP와 DNS 이름을 등록하여, DNS 이름을 기반으로 리소스에 접근할 수 있도록 한다.

---

# 2. 워커 노드(Kubernetes Node)

![https://galid1.tistory.com/413](https://t1.daumcdn.net/cfile/tistory/99D6D04A5C4D758219)

마스터에 의해 명령을 받고, 실제 워크 로드를 생성해서 서비스하는 컴포넌트이다. 실제 컨테이너들이 생성되는 가상머신 또는 물리적인 서버를 의미하고, 각각 서버에 라벨을 붙여서 사용 목적을 정의할 수도 있다. API 서버의 요청은 kubelet을 통해 수행한다.

## 2.1 kubelet

노드에 배포되는 agent. 마스터 노드의 API 서버와 통신하는 컴포넌트이다.

1. 마스터 노드의 API 서버로부터 수행할 명령을 받아서 워커 노드를 수행시킴.
2. 워커 노드의 상태를 마스터 노드로 전달함.

노드에 할당된 pod들의 생명주기를 관리한다. pod를 생성하고 pod안의 컨테이너에 이상이 없는지 확인하면서 노드의 상태를 마스터 노드에게 전달한다. API 서버의 요청을 받아서 컨테이너의 로그를 전달하거나, 특정 명령을 대신 수행하기도 한다.

Scheduler에 의해 pod가 스케줄링되면, API 서버는 Kubelet에게 pod를 생성하라는 요청을 보낸다. 이 요청을 받은 kubelet은 지정된 컨테이너 런타임과 이미지를 사용해 컨테이너를 생성한다. 또한, 실행 중인 컨테이너를 모니터링하며 관련된 정보를 API 서버에게 보낸다. 추가로, liveness probe가 설정되어 있는 경우, 컨테이너를 재시작하는 역할도 kubelet에서 담당한다.

## 2.2 kube-proxy

노드에 할당된 pod로 연결되는 네트워크를 관리한다. 노드로 오는 트래픽을 적절한 컨테이너로 프록시 하고, 노드와 마스터 간의 네트워크 통신을 관리한다.

클러스터 내부에 별도의 가상 네트워크가 동작할 수 있게 해 주는 프로세스이다. TCP, UDP, SCTP 스트림을 포워딩하고, 여러 개의 pod를 round robin 형태로 묶어서 서비스를 제공한다.(라운드 로빈, 즉, 일정 주기마다 트래픽을 전달하는 대상 pod를 교체한다는 소리인듯) 노드로 들어오는 트래픽을 적절한 컨테이너로 라우팅, 로드밸런싱, 프록시하면서 통신을 관리한다.

kube-proxy는 서비스의 IP 및 포트로 들어온 접속을 서비스의 엔드포인트에 해당하는 pod에 연결하는 역할을 담당한다. proxy라는 이름이 붙은 이유는 초기 쿠버네티스 버전에서 kube-proxy는 userspace에서 동작하던 프록시였기 때문이다. 하지만, 현재는 성능이 더 우수한 iptables 프록시 모드로 수행된다. [https://coffeewhale.com/k8s/network/2019/05/11/k8s-network-02/](https://coffeewhale.com/k8s/network/2019/05/11/k8s-network-02/)

## 2.3 Container Runtime

pod를 통해 배포된 컨테이너를 실제로 실행시킨다. 컨테이너 런타임 중에 대표적인 예로는 도커(Docker)가 있고, 그 외에 rkt, runC 같은 런타임도 지원한다. CRI(Container Runtime Interface)를 구현한 다양한 런타임을 지원한다.

## 2.4 cAdvisor

각 노드에서 기동되는 모니터링 agent이다. 노드에서 가동되는 컨테이너들의 상태 정보를 수집해서 마스터의 API 서버로 전달한다.

[쿠버네티스 아키텍쳐(2/2) (마스터노드/워커노드)](https://pearlluck.tistory.com/136)

[[Kubernetes 내부 구조 이해하기] 1. 쿠버네티스 클러스터 구성 요소](https://sphong0417.tistory.com/53)

[](https://bcho.tistory.com/1256)

[쿠버네티스 안전하게 사용하기 - 배경](https://blog.secunologylab.com/Kubernetes-usage-safety-background/)

영어라서 정리는 못했지만, kubernetes community에서 정리한 쿠버네티스 글

[community/architecture.md at master · kubernetes/community](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/architecture.md)